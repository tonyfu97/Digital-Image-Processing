<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Tony Fu" /><link rel="canonical" href="https://tonyfu97.github.io/Digital-Image-Processing/06_feature_extraction/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>6. Feature Extraction - Digital Image Processing Notes</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "6. Feature Extraction";
        var mkdocs_page_input_path = "06_feature_extraction.md";
        var mkdocs_page_url = "/Digital-Image-Processing/06_feature_extraction/";
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/django.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-274394082"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-274394082');
      </script>
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Digital Image Processing Notes
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../01_getting_started/">1. Getting Started</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../02_block_decomposition/">2. Block Decomposition</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../03_point_processing/">3. Point Processing Transformations</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../04_morphology/">4. Morphology</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../05_filtering/">5. Filtering</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">6. Feature Extraction</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#1-harris-stephens-corner-detector">1. Harris-Stephens Corner Detector</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#11-gradient-calculation">1.1 Gradient Calculation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#12-structure-tensor">1.2 Structure Tensor</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#13-r-function-calculation">1.3 R Function Calculation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#14-local-maxima-detection">1.4 Local Maxima Detection</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#15-sorting-the-corners">1.5 Sorting the Corners</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#2-shi-tomasi-algorithm">2. Shi-Tomasi Algorithm</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#3-hough-transform">3. Hough Transform</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#31-initializing-variables">3.1 Initializing Variables</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#32-gradient-calculation-and-smoothing">3.2 Gradient Calculation and Smoothing</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#33-hough-space-calculation">3.3 Hough Space Calculation</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#331-calculating-the-gradient-and-the-angles">3.3.1 Calculating the Gradient and the Angles</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#332-calculating-rho">3.3.2 Calculating \rho</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#333-adjusting-rho-and-theta">3.3.3 Adjusting \rho and \theta</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#334-populating-the-accumulator">3.3.4 Populating the Accumulator</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#34-accumulator-smoothing-and-thresholding">3.4 Accumulator Smoothing and Thresholding</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#35-line-display">3.5 Line Display</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#circle-detection">Circle Detection</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#4-texture-spectrum">4. Texture Spectrum</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#5-tamura-coefficients">5. Tamura Coefficients</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#51-contrast">5.1 Contrast</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#52-coarseness">5.2 Coarseness</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#53-directionality">5.3 Directionality</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#6-local-binary-pattern-lbp">6. Local Binary Pattern (LBP)</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#61-sampling-p-points-on-a-circle-of-radius-r">6.1 Sampling p Points on a Circle of Radius R</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#62-computing-uniformity-u">6.2 Computing Uniformity (U)</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#63-computing-lbp">6.3 Computing LBP</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../07_segmentation/">7. Segmentation</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../08_motion/">8. Motion Estimation</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../appendix_1/">Appendix 1 - Math Expressions in CImg's Fill Method</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../where_did_i_get_my_images/">Where Did I Get My Images?</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Digital Image Processing Notes</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a> &raquo;</li>
      <li>6. Feature Extraction</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/tonyfu97/Digital-Image-Processing/blob/master/docs/06_feature_extraction.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="feature-extraction-learning-reflection">Feature Extraction - Learning Reflection</h1>
<p><strong>Author</strong>: Tony Fu<br />
<strong>Date</strong>: August 23, 2023<br />
<strong>Device</strong>: MacBook Pro 16-inch, Late 2021 (M1 Pro)<br />
<strong>Code</strong>: <a href="https://github.com/tonyfu97/Digital-Image-Processing/tree/main/06_feature_extraction">GitHub</a><br />
<strong>Reference</strong>: Chapter 6 <a href="https://www.amazon.com/Digital-Image-Processing-Implementing-Algorithms/dp/1032347538"><em>Digital Image Processing with C++: Implementing Reference Algorithms with the CImg Library</em> by Tschumperl√©, Tilmant, Barra</a></p>
<h2 id="1-harris-stephens-corner-detector">1. Harris-Stephens Corner Detector</h2>
<p>I love the explanation of the Corner detection by Professor Shree K. Nayar (<a href="https://youtu.be/Z_HwkG90Yvw">Video link</a>). Here is the summary:</p>
<p>The Harris-Stephens corner detection algorithm is designed to identify regions where there are substantial variations in gradient in two distinct directions. While it might be simple to detect corners aligned with the x and y axes, real-world images present corners at various angles. This challenge is addressed by using the determinant, which gives a measure of how well-separated the two gradient directions are. A larger determinant typically signifies a strong presence of two different gradient directions. However, an excessively large axis in one direction could mislead the interpretation. To counterbalance this, the algorithm subtracts a term related to the trace, squared and weighted by a parameter, from the determinant. This penalizes the response value <script type="math/tex">R</script> and aids in distinguishing between genuine corners and edges or flat regions, leading to more accurate corner detection. Here are the steps:</p>
<h3 id="11-gradient-calculation">1.1 Gradient Calculation</h3>
<p>The gradient of the input image is calculated using:
<script type="math/tex; mode=display"> \text{{gradXY}} = \text{{imgIn.get_gradient()}}; </script>
This gets the gradients in the x and y directions.</p>
<h3 id="12-structure-tensor">1.2 Structure Tensor</h3>
<pre><code class="language-cpp">CImg&lt;&gt;
    Ixx = gradXY[0].get_mul(gradXY[0]).get_convolve(G),
    Iyy = gradXY[1].get_mul(gradXY[1]).get_convolve(G),
    Ixy = gradXY[0].get_mul(gradXY[1]).get_convolve(G);
</code></pre>
<p>The structure tensor is computed as:
<script type="math/tex; mode=display">
\begin{align*}
I_{xx} &= \text{{gradXY[0].get_mul(gradXY[0]).get_convolve(G)}}, \\
I_{yy} &= \text{{gradXY[1].get_mul(gradXY[1]).get_convolve(G)}}, \\
I_{xy} &= \text{{gradXY[0].get_mul(gradXY[1]).get_convolve(G)}}.
\end{align*}
</script>
</p>
<p>where the Gaussian kernel <script type="math/tex">G</script> is defined as:
<script type="math/tex; mode=display"> G(x, y) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2 + y^2}{2\sigma^2}} </script>
</p>
<p>Together, we can build the structure tensor <script type="math/tex">M</script> as:</p>
<p>
<script type="math/tex; mode=display">
M = \begin{bmatrix} I_{xx} & I_{xy} \\ I_{xy} & I_{yy} \end{bmatrix}
</script>
</p>
<p>The determinant of <script type="math/tex">M</script> (<script type="math/tex">\det(M)</script>) and the trace of <script type="math/tex">M</script> (<script type="math/tex">\text{trace}(M)</script>) are computed as follows:</p>
<p>
<script type="math/tex; mode=display">\det(M) = I_{xx} \cdot I_{yy} - I_{xy} \cdot I_{xy}</script>
</p>
<p>
<script type="math/tex; mode=display">\text{trace}(M) = I_{xx} + I_{yy}</script>
</p>
<p>The structure tensor <script type="math/tex">M</script> plays a key role in feature detection as it represents the distribution of gradients within a specific neighborhood around a point. Rather than directly comparing the gradient of a pixel with those of its neighbors, we use a Gaussian function to calculate an average gradient across an area.</p>
<p>In essence, the structure tensor captures the underlying geometric structure in the vicinity of each pixel. It accomplishes this by portraying gradient orientations as an ellipse in the (<script type="math/tex">I_x, I_y</script>) plane within a specific window. Here, the determinant is directly proportional to the area of the ellipse, while the trace is equivalent to the sum of the lengths of the ellipse's major and minor axes.</p>
<ul>
<li>
<p><strong>Presence of an edge</strong>: When an image contains an edge, the distribution of gradients forms a slender, elongated ellipse. This happens because the intensity changes consistently in one direction (along the edge) and shows little to no change in the direction perpendicular to it. The major axis of this ellipse aligns with the direction of the edge.</p>
</li>
<li>
<p><strong>Presence of a corner</strong>: If a corner is present, the gradients are distributed more evenly, resulting in an elliptical shape that resembles a circle. This is because a corner features significant intensity changes in multiple directions.</p>
</li>
<li>
<p><strong>Flat region</strong>: In a flat region of the image, where there is minimal change in intensity in any direction, the ellipse is small, signaling the absence of distinctive features.</p>
</li>
</ul>
<h3 id="13-r-function-calculation">1.3 R Function Calculation</h3>
<pre><code class="language-cpp">CImg&lt;&gt;
    det = Ixx.get_mul(Iyy) - Ixy.get_sqr(),
    trace = Ixx + Iyy,
    R = det - k * trace.get_sqr();
</code></pre>
<p>Often, in the theoretical explanation of the Harris-Stephens corner detection algorithm, we will see the eigenvalues <script type="math/tex">\lambda_1</script> and <script type="math/tex">\lambda_2</script> are often introduced to provide an intuitive understanding of the underlying geometric properties of the image. However, in the actual implementation, you can compute the response function <script type="math/tex">R</script> directly from the components of the second-moment matrix <script type="math/tex">I_{xx}</script>, <script type="math/tex">I_{yy}</script>, and <script type="math/tex">I_{xy}</script>, without having to explicitly calculate the eigenvalues. It is given as:
<script type="math/tex; mode=display"> R = \det - \, k \cdot \text{{trace}}^2 = (I_{xx} \cdot I_{yy} - I_{xy}^2) - k \cdot (I_{xx} + I_{yy})^2</script>
</p>
<table>
<thead>
<tr>
<th>Condition</th>
<th>Region Type</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr>
<td>R is close to 0</td>
<td>Flat Region</td>
<td>No significant change in intensity in any direction, both eigenvalues of the structure tensor are small.</td>
</tr>
<tr>
<td>R is small</td>
<td>Edge</td>
<td>Significant change in intensity in one direction but not the other, one large and one small eigenvalue of the structure tensor.</td>
</tr>
<tr>
<td>R is positive</td>
<td>Corner</td>
<td>Significant changes in intensity in both directions, both eigenvalues of the structure tensor are large, indicating two dominant and different edge directions.</td>
</tr>
</tbody>
</table>
<h3 id="14-local-maxima-detection">1.4 Local Maxima Detection</h3>
<pre><code class="language-cpp">CImgList&lt;&gt; imgGradR = R.get_gradient();
CImg_3x3(I, float);
CImg&lt;&gt; harrisValues(imgIn.width() * imgIn.height(), 1, 1, 1, 0);
CImg&lt;int&gt;
    harrisXY(imgIn.width() * imgIn.height(), 2, 1, 1, 0),
    perm(imgIn.width() * imgIn.height(), 1, 1, 1, 0);
int nbHarris = 0;
cimg_for3x3(R, x, y, 0, 0, I, float)
{
    if (imgGradR[0](x, y) &lt; eps &amp;&amp; imgGradR[1](x, y) &lt; eps)
    {
        float
            befx = Ipc - Icc,
            befy = Icp - Icc,
            afty = Icn - Icc,
            aftx = Inc - Icc;
        if (befx &lt; 0 &amp;&amp; befy &lt; 0 &amp;&amp; aftx &lt; 0 &amp;&amp; afty &lt; 0)
        {
            harrisValues(nbHarris) = R(x, y);
            harrisXY(nbHarris, 0) = x;
            harrisXY(nbHarris++, 1) = y;
        }
    }
}
</code></pre>
<p>Local maxima of the <script type="math/tex">R</script> function are detected. This part of the code finds points that are potential corners.</p>
<h3 id="15-sorting-the-corners">1.5 Sorting the Corners</h3>
<pre><code class="language-cpp">harrisValues.sort(perm, false);
</code></pre>
<p>The values are sorted, and the top <script type="math/tex"> n </script> corners are drawn on the image. In other implementations, this step is usually replaced by non-maximum suppression.</p>
<p><img alt="harris" src="../results/06/lighthouse_harris.png" /></p>
<h2 id="2-shi-tomasi-algorithm">2. Shi-Tomasi Algorithm</h2>
<p>Shi-Tomasi algorithm uses similar techniques to compute eigenvalues that represent the local structure of the image, but it applies a different criteria to determine if a region is a corner:</p>
<p>
<script type="math/tex; mode=display">
R = \min(\lambda_1, \lambda_2)
</script>
</p>
<p>The algorithm is implemented as follows:</p>
<pre><code class="language-cpp">CImg&lt;&gt;
    det = Ixx.get_mul(Iyy) - Ixy.get_sqr(),
    trace = Ixx + Iyy,
    diff = (trace.get_sqr() - 4 * det).sqrt(),
    lambda1 = (trace + diff) / 2,
    lambda2 = (trace - diff) / 2,
    R = lambda1.min(lambda2);
</code></pre>
<p><img alt="shi-tomasi" src="../results/06/lighthouse_shi_tomasi.png" /></p>
<p>Shi-Tomasi's reliance on the minimum eigenvalue often leads to better detection of true corners. Not sure about this one.</p>
<h2 id="3-hough-transform">3. Hough Transform</h2>
<p>Again, I recommend watching Professor Shree K. Nayar's <a href="https://youtu.be/XRBc_xkZREg?si=WBN-WPRsqEndBMcA">video</a> on the Hough Transform. Here's a summary:</p>
<p>The Hough Transform is a technique used to detect shapes that can be represented by a mathematical equation. It's particularly useful for finding lines and circles. Essentially, it involves a "transformation" from the image space to the parameter space.</p>
<p>For detecting lines, you might represent them with the equation <script type="math/tex">y = mx + b</script>, where the parameter space consists of the slope <script type="math/tex">m</script> and the intercept <script type="math/tex">b</script>. However, this representation can be problematic since the slope <script type="math/tex">m</script> can become infinite. A better approach uses the polar form <script type="math/tex">r = x \cos \theta + y \sin \theta</script>, where <script type="math/tex">r</script> is the distance from the origin to the line, and <script type="math/tex">\theta</script> is the angle between the line and the x-axis. In this case, the parameter space is defined by <script type="math/tex">r</script> and <script type="math/tex">\theta</script>.</p>
<p>This parameter space is divided into a grid, where each cell represents a potential line in the image space. The algorithm then iterates through each pixel in the image space, incrementing the corresponding cell in the parameter space. The cell with the highest count (or "votes," as Professor Nayar puts it) represents the detected line.</p>
<table>
<thead>
<tr>
<th>Shape in Image Space</th>
<th>Representation in Parameter Space</th>
<th>Parameters</th>
<th>Equation (if applicable)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Line</td>
<td>Point</td>
<td>Slope (m), Intercept (b)</td>
<td>
<script type="math/tex"> y = mx + b </script>
</td>
</tr>
<tr>
<td>Line (Polar Form)</td>
<td>Sinusoidal Curve</td>
<td>Distance (r), Angle (Œ∏)</td>
<td>
<script type="math/tex"> r = x \cos \theta + y \sin \theta </script>
</td>
</tr>
<tr>
<td>Circle</td>
<td>3D Surface</td>
<td>Center (a, b), Radius (r)</td>
<td>
<script type="math/tex"> (x - a)^2 + (y - b)^2 = r^2 </script>
</td>
</tr>
<tr>
<td>Ellipse</td>
<td>4D Surface</td>
<td>Center (a, b), Major/Minor Axes (r1, r2)</td>
<td>
<script type="math/tex"> \frac{{(x - a)^2}}{{r1^2}} + \frac{{(y - b)^2}}{{r2^2}} = 1 </script>
</td>
</tr>
</tbody>
</table>
<h3 id="31-initializing-variables">3.1 Initializing Variables</h3>
<p>The code starts by defining variables for the accumulator, image dimensions, and bounds of the parameters.</p>
<pre><code class="language-cpp">CImg&lt;&gt;
    acc(500, 400, 1, 1, 0),
    imgOut(imgIn);
int
    wx = imgIn.width(),
    wy = imgIn.height();

float
    rhomax = std::sqrt((float)(wx * wx + wy * wy)) / 2,
    thetamax = 2 * cimg::PI;
</code></pre>
<h3 id="32-gradient-calculation-and-smoothing">3.2 Gradient Calculation and Smoothing</h3>
<p>The code calculates the gradient of the input image and applies a blur to smooth it.</p>
<pre><code class="language-cpp">CImgList&lt;&gt; grad = imgIn.get_gradient();
cimglist_for(grad, l)
    grad[l].blur(1.5f);
</code></pre>
<h3 id="33-hough-space-calculation">3.3 Hough Space Calculation</h3>
<p>The Hough space is a mathematical representation that helps in identifying lines in an image. In the Hough space, a line can be represented by two parameters: <script type="math/tex">\rho</script> and <script type="math/tex">\theta</script>, where <script type="math/tex">\rho</script> (same as <script type="math/tex"> r</script> mentioned above) is the distance from the origin to the closest point on the straight line, and <script type="math/tex">\theta</script> is the angle formed by this perpendicular line and the horizontal axis.</p>
<h4 id="331-calculating-the-gradient-and-the-angles">3.3.1 Calculating the Gradient and the Angles</h4>
<p>The code snippet begins by iterating over all the pixels in the input image to calculate the gradient at each pixel:</p>
<pre><code class="language-cpp">float
    X = (float)x - wx / 2,
    Y = (float)y - wy / 2,
    gx = grad(0, x, y),
    gy = grad(1, x, y),
    theta = std::atan2(gy, gx);
</code></pre>
<p>Here, <script type="math/tex">X</script> and <script type="math/tex">Y</script> represent the coordinates if the origin is at the center of the image. The gradient at each pixel is given by <script type="math/tex">(gx, gy)</script>, and <script type="math/tex">\theta</script> is calculated using the arctangent function, which gives the angle of the gradient vector.</p>
<h4 id="332-calculating-rho">3.3.2 Calculating <script type="math/tex">\rho</script>
</h4>
<p>Next, the code calculates <script type="math/tex">\rho</script> as follows:</p>
<pre><code class="language-cpp">rho = std::sqrt(X * X + Y * Y) * std::cos(std::atan2(Y, X) - theta);
</code></pre>
<p>The value of <script type="math/tex">\rho</script> is computed using the distance formula and the cosine of the difference between the angle of the vector to the origin <script type="math/tex">(X, Y)</script> and <script type="math/tex">\theta</script>.</p>
<h4 id="333-adjusting-rho-and-theta">3.3.3 Adjusting <script type="math/tex">\rho</script> and <script type="math/tex">\theta</script>
</h4>
<p>If <script type="math/tex">\rho</script> is negative, it's multiplied by -1, and <script type="math/tex">\theta</script> is adjusted by adding <script type="math/tex">\pi</script>:</p>
<pre><code class="language-cpp">if (rho &lt; 0)
{
    rho *= -1;
    theta += cimg::PI;
}
theta = cimg::mod(theta, thetamax);
</code></pre>
<p>This ensures that <script type="math/tex">\rho</script> is positive, and <script type="math/tex">\theta</script> is within the valid range.</p>
<h4 id="334-populating-the-accumulator">3.3.4 Populating the Accumulator</h4>
<p>Finally, the accumulator is updated based on the calculated <script type="math/tex">\rho</script> and <script type="math/tex">\theta</script>:</p>
<pre><code class="language-cpp">acc((int)(theta * acc.width() / thetamax), (int)(rho * acc.height() / rhomax)) += (float)std::sqrt(gx * gx + gy * gy);
</code></pre>
<p><img alt="road_hough_raw_0.9" src="../results/06/road_hough_raw_0.9.png" /></p>
<p>The accumulator's cell corresponding to <script type="math/tex">\rho</script> and <script type="math/tex">\theta</script> is incremented by the magnitude of the gradient. This process effectively votes for the parameters of the line that the current pixel might be part of. By the end of this process, the accumulator will contain information about the lines present in the image, represented in the Hough space.</p>
<h3 id="34-accumulator-smoothing-and-thresholding">3.4 Accumulator Smoothing and Thresholding</h3>
<p>The accumulator is smoothed and thresholded to identify significant lines.</p>
<pre><code class="language-cpp">// Smoothing the accumulators.
acc.blur(0.5f);
CImg&lt;&gt; acc2(acc);

// Log transform to enhance the contrast of small values.
cimg_forXY(acc2, x, y)
    acc2(x, y) = (float)std::log(1 + acc(x, y));

// Thresholding and filtering the accumulators.
int size_max = acc2.get_threshold(thr * acc2.max()).get_label().max();
CImg&lt;int&gt; coordinates(size_max, 2, 1, 1, 0);
int accNumber = 0;
AccThreshold(acc2, thr * acc2.max(), 4, coordinates, accNumber);
</code></pre>
<p>The <code>AccThreshold()</code> function is also defined in <code>hough.cpp</code>. It modifies <code>coordinates</code> and <code>accNumber</code> in place. <code>coordinates</code> contains the coordinates of the local maxima in the accumulator grid that are above the given threshold, and <code>accNumber</code> contains the count of such maxima. The image below shows the accumulator after smoothing and thresholding with a threshold value of 0.9.</p>
<p><img alt="road_hough_thresholded_0.9" src="../results/06/road_hough_thresholded_0.9.png" /></p>
<h3 id="35-line-display">3.5 Line Display</h3>
<p>Finally, the detected lines are drawn on the output image using the calculated rho and theta values.</p>
<pre><code class="language-cpp">unsigned char col1[3] = {255, 255, 0};
for (unsigned i = 0; i &lt; accNumber; ++i)
{
    // Drawing lines
    // ...
    imgOut.draw_line(x0, y0, x1, y1, col1, 1.0f).draw_line(x0 + 1, y0, x1 + 1, y1, col1, 1.0f).draw_line(x0, y0 + 1, x1, y1 + 1, col1, 1.0f);
}
return imgOut;
</code></pre>
<ul>
<li><strong>Threshold = 0.6</strong></li>
</ul>
<p><img alt="road_hough_0.60" src="../results/06/road_hough_0.60.png" /></p>
<ul>
<li><strong>Threshold = 0.7</strong></li>
</ul>
<p><img alt="road_hough_0.70" src="../results/06/road_hough_0.70.png" /></p>
<ul>
<li><strong>Threshold = 0.8</strong></li>
</ul>
<p><img alt="road_hough_0.80" src="../results/06/road_hough_0.80.png" /></p>
<ul>
<li><strong>Threshold = 0.9</strong></li>
</ul>
<p><img alt="road_hough_0.90" src="../results/06/road_hough_0.90.png" /></p>
<h3 id="circle-detection">Circle Detection</h3>
<p>The Hough Transform can also be used to detect circles. In this case, the parameter space is 3D, with the parameters being the center of the circle <script type="math/tex">(xc, yc)</script> and the radius <script type="math/tex">r</script>. The equation of a circle is given by:
<script type="math/tex; mode=display"> (x - xc)^2 + (y - yc)^2 = r^2 </script>
</p>
<p>See <code>hough_circle.cpp</code> for the implementation.</p>
<p>Starting with a binarized image of coins:</p>
<p><img alt="coins_median" src="../results/06/coins_median.png" /></p>
<p>The Hough Transform is applied to detect the circles:</p>
<p><img alt="coins_hough" src="../results/06/coins_hought_circle.png" /></p>
<p>The middle coin at the bottom was not detected perhaps because the binarization process caused it to be broken.</p>
<h2 id="4-texture-spectrum">4. Texture Spectrum</h2>
<p><a href="https://www.sciencedirect.com/science/article/pii/0031320390901358?via=ihub">He and Wang (1990)</a> proposed a method to characterize textures in an image. As the first step of most algorithms, we break down the problem into smaller pieces. Instead of characterizing the whole image at once, we analyze each pixel individually. For each pixel, we define a so-called <em>texture unit</em>, a vector of size 8 <script type="math/tex">\{E_1, E_2, E_3, \ldots\}</script>. The formula for <script type="math/tex">E_i</script> is given as:</p>
<p>
<script type="math/tex; mode=display">
\begin{equation}
\text{E_i}(v_1, v_2, \tau) = 
\begin{cases} 
  0 & \text{if } v_1 < v_2 - \tau \\
  1 & \text{if } \left| v_1 - v_2 \right| \leq \tau \\
  2 & \text{otherwise}
\end{cases}
\end{equation}
</script>
</p>
<p>where <script type="math/tex">v_1</script> is the pixel value of the i-th neighboring pixel, and <script type="math/tex">v_2</script> is the pixel value of the current pixel. <script type="math/tex">\tau</script> is a threshold that determines sensitivity. Here is an diagram that illustrates the calculation of <script type="math/tex">E_i</script>:</p>
<p><img alt="texture_spectrum" src="../results/06/texture_spectrum.png" /></p>
<p>Next, we summarize this texture unit, which is a vector of size 8, into a single value:</p>
<p>
<script type="math/tex; mode=display">
N = \sum_{i=1}^{8} 3^{i-1} E_i
</script>
</p>
<p>To visualize this texture encoding, let's consider the original image:</p>
<p><img alt="farm" src="../images/farm.png" /></p>
<p>And here is the texture encoding (using <script type="math/tex">\tau = 5</script>):</p>
<p><img alt="farm_texture_spectrum" src="../results/06/farm_texture_spectrum.png" /></p>
<p>To obtain the texture spectrum, we go through each pixel and calculate the texture encoding. Then, we plot the histogram of the texture encodings. This histogram represents the texture spectrum of the image:</p>
<p><img alt="farm_texture_spectrum_histogram" src="../results/06/farm_texture_spectrum_histogram.png" /></p>
<p>The sharp peak in the middle means that most texture units are encoded as a vector of ones. This is because the image contains a lot of flat regions.</p>
<h2 id="5-tamura-coefficients">5. Tamura Coefficients</h2>
<p><a href="https://ieeexplore.ieee.org/document/4309999">Tamura et al. (1978)</a> introduce six texture features that are considered to correspond well to human visual perception. These features were proposed to capture essential characteristics of visual textures that humans typically recognize. The six texture features are: <strong>Coarseness</strong>, <strong>Contrast</strong>, <strong>Directionality</strong>, <strong>Line-Likeness</strong>, <strong>Regularity</strong>, and <strong>Roughness</strong>. The book only covers the first three, so I will only discuss those.</p>
<h3 id="51-contrast">5.1 Contrast</h3>
<p>Tamura's contrast is defined as the ratio of the standard deviation to the kurtosis of the image's pixel values.</p>
<p>
<script type="math/tex; mode=display">
Contrast = \frac{\sigma}{\kappa^n}
</script>
</p>
<p>Here, <script type="math/tex"> \sigma^2 </script> is the variance, <script type="math/tex"> \kappa </script> is the kurtosis, and <script type="math/tex"> n </script> is a given exponent (I use 0.5). The book has made a mistake to calculate this value based on the histogram counts, which is not the usual way to calculate these statistics for Tamura's contrast.</p>
<p>The reason kurtosis is included in the formula is that standard deviation alone may not provide a complete picture of how most pixels are distributed within the image. This is because standard deviation is highly sensitive to outliers. While outliers might not significantly alter our perception of contrast in an image, they can dramatically increase the value of the standard deviation. By dividing the standard deviation by the kurtosis, the formula incorporates a term that mitigates the impact of outliers, providing a more accurate measure of contrast that aligns with human perception.</p>
<p>For this following image, the contrast is calculated to be 1,158,660:</p>
<p><img alt="car" src="../images/car.png" /></p>
<p>After normalizing the image to be between (50, 200), the contrast decreases to 235,809:</p>
<p><img alt="car_low_contrast" src="../results/06/car_low_contrast.png" /></p>
<h3 id="52-coarseness">5.2 Coarseness</h3>
<p>Four functions work together to compute Tamura's coarseness in an image. The functions provide a series of steps, calculating integral means, local means, differences, and coarseness. The functions are as follows:</p>
<ol>
<li>
<p><strong><code>IntegralMean</code></strong>: This function calculates the local mean within a window of size <code>k</code> around a given pixel <code>(x,y)</code> using the integral image. The integral image helps to compute sum queries over image subregions efficiently.</p>
</li>
<li>
<p><strong><code>ComputeAk</code></strong>: Computes the local means at different scales using the <code>IntegralMean</code> function. This will provide an image <code>Ak</code> where each pixel holds the average intensity of its surrounding pixels for different window sizes.</p>
</li>
<li>
<p><strong><code>ComputeE</code></strong>: Calculates the absolute differences between local means at different scales, creating two images <code>Ekh</code> and <code>Ekv</code>, representing horizontal and vertical differences. These capture texture changes in different directions.</p>
</li>
<li>
<p><strong><code>ComputeS</code></strong>: Uses <code>Ekh</code> and <code>Ekv</code> to compute Tamura's coarseness measure. It calculates the scale at which the largest difference between neighboring local means is observed.</p>
</li>
</ol>
<p>The formulas represented by the functions are as follows:</p>
<ul>
<li>
<p><strong>Horizontal and Vertical Differences (<code>Ekh</code>, <code>Ekv</code>)</strong>:
  <script type="math/tex; mode=display">
  E_k^h(x, y) = |A_k(x + 2^{k-1}, y) - A_k(x - 2^{k-1}, y)|
  </script>
<script type="math/tex; mode=display">
  E_k^v(x, y) = |A_k(x, y + 2^{k-1}) - A_k(x, y - 2^{k-1})|
  </script>
  where <script type="math/tex">A_k</script> is the local mean at scale <script type="math/tex">k</script>.</p>
</li>
<li>
<p><strong>Coarseness (<code>ComputeS</code>)</strong>:
  <script type="math/tex; mode=display">
  Coarseness = \frac{{\sum_{x,y} 2^{k_{\text{max}}(x,y)}}}{{\text{width} \times \text{height}}}
  </script>
  where <script type="math/tex"> k_{\text{max}}(x,y) </script> is the scale at which the maximum difference is found for pixel <script type="math/tex"> (x,y) </script>.</p>
</li>
</ul>
<p>For the following image, the coarseness is calculated to be 25.244:</p>
<p><img alt="farm" src="../images/farm.png" /></p>
<p>After Gaussian blur with a sigma of 5, the coarseness <strong>increases</strong> to 28.919:</p>
<p><img alt="farm_smooth" src="../results/06/farm_smooth.png" /></p>
<p>The unexpected behavior may be due to the interpretation of what coarseness means in this context. In Tamura's coarseness, it's not necessarily related to roughness but more about the granularity or scale of the texture. A smoother image may have larger, more uniform regions, which would be captured by this measure as being "coarser."</p>
<h3 id="53-directionality">5.3 Directionality</h3>
<p>Tamura's directionality coefficient aims to quantify the extent and directionality of edge-like features in an image. Higher values often indicate more dominant directions in the textures or features of the image.</p>
<p>The formula for directionality look like:</p>
<p>
<script type="math/tex; mode=display">
D = 1 + r \times \text{nb_pics} \times \sum_{p=0}^{\text{nb_pics}} \sum_{x} [ -h(x) \times (x - \text{perm}(p))^2 ]
</script>
</p>
<p>Here, <script type="math/tex"> \text{nb_pics} </script> is the number of maxima in the histogram, and <script type="math/tex"> r </script> is a constant set to 1 in your code.</p>
<p>The following are a few texture images with their directionality coefficients:</p>
<p><img alt="directionality_results" src="../results/06/directionality_results.png" /></p>
<h2 id="6-local-binary-pattern-lbp">6. Local Binary Pattern (LBP)</h2>
<p>I appreciate the explanation of LBP by <a href="https://youtu.be/_5ktOnEZ3O4?si=N8WPh3r5gyv6pu1v">Moacir Antonelli Ponti</a>. It's worth noting that the implementation from the book, which is also used here, is simplified. Specifically, it lacks translation invariance, and sequences of <script type="math/tex">U</script> with an identical number of '1's are treated as equivalent (e.g., {0101} and {0011}).</p>
<h3 id="61-sampling-p-points-on-a-circle-of-radius-r">6.1 Sampling <script type="math/tex">p</script> Points on a Circle of Radius <script type="math/tex">R</script>
</h3>
<p>The first step involves sampling <script type="math/tex">p</script> points on a circle with radius <script type="math/tex">R</script>. In the example code from the book, <script type="math/tex">p=20</script> and <script type="math/tex">R=2</script>. These sampled points likely won't align with the pixel grid, so interpolation using <code>CImg&lt;&gt;linear_atXY(x, y)</code> is necessary.</p>
<h3 id="62-computing-uniformity-u">6.2 Computing Uniformity (<script type="math/tex">U</script>)</h3>
<p>This is the step where LBP earns its "binary" moniker. For each point, we compare its value <script type="math/tex">V(n)</script> to the value <script type="math/tex">V_c</script> of the central pixel as well as the value of the preceding point <script type="math/tex">V(n-1)</script>:</p>
<p>
<script type="math/tex; mode=display">
U = \sum_{n=0}^{p-1} \left[ \left( V(n) - V_c > 0 \right) - \left( V(n-1) - V_c > 0 \right) \right]
</script>
</p>
<p>Here, <script type="math/tex">V(n)</script> is the value of the sampled point, and <script type="math/tex">V_c</script> is the value of the center pixel. If <script type="math/tex">n=0</script>, <script type="math/tex">V(n-1)</script> is out of range, so we use <script type="math/tex">V(p-1)</script>.</p>
<h3 id="63-computing-lbp">6.3 Computing LBP</h3>
<p>We categorize the <script type="math/tex">LBP</script> value by comparing <script type="math/tex">U</script> with 2. If <script type="math/tex">U > 2</script>, indicating a non-uniform pattern (i.e., more than two transitions between 0 and 1), we label it with a special value <script type="math/tex">p+1</script>. Otherwise, the following applies:</p>
<p>
<script type="math/tex; mode=display">
\begin{cases} 
  lbp(x,y) = p+1 & \text{if } U > 2 \\
  lbp(x,y) = \sum_{n=0}^{p-1} \left[ V(n) - V_c > 0 \right] & \text{otherwise}
\end{cases}
</script>
</p>
<p>Using a small subset of textures from the <a href="https://www.kaggle.com/datasets/jmexpert/describable-textures-dataset-dtd">Describable Textures Dataset (DTD)</a> (found in the "textures" folder), I got some interesting results:</p>
<p><img alt="lbp_example1" src="../results/06/lbp_example1.png" /></p>
<p>The example above demonstrates that LBP can capture the "fibrous" texture in the original image.</p>
<p><img alt="lbp_example2" src="../results/06/lbp_example2.png" /></p>
<p>Similarly, LBP worked well for a "grid" texture, as can be seen from the top-1 result.</p>
<p><img alt="lbp_example3" src="../results/06/lbp_example3.png" /></p>
<p>However, LBP struggled to capture the "banded" texture effectively, as the top results don't look like the original image.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../05_filtering/" class="btn btn-neutral float-left" title="5. Filtering"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../07_segmentation/" class="btn btn-neutral float-right" title="7. Segmentation">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
      <p>Copyright &copy; 2023 Tony Fu</p>
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/tonyfu97/Digital-Image-Processing" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../05_filtering/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../07_segmentation/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>

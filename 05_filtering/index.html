<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Tony Fu" /><link rel="canonical" href="https://tonyfu97.github.io/Digital-Image-Processing/05_filtering/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>5. Filtering - Digital Image Processing Notes</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "5. Filtering";
        var mkdocs_page_input_path = "05_filtering.md";
        var mkdocs_page_url = "/Digital-Image-Processing/05_filtering/";
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/django.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-274394082"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-274394082');
      </script>
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Digital Image Processing Notes
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../01_getting_started/">1. Getting Started</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../02_block_decomposition/">2. Block Decomposition</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../03_point_processing/">3. Point Processing Transformations</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../04_morphology/">4. Morphology</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">5. Filtering</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#1-convolution">1. Convolution</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#boundary-conditions">Boundary Conditions</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#2-median-fitler">2. Median Fitler</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#order-statistic-os-filter">Order-Statistic (OS) Filter</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#3-first-order-derivatives">3. First-Order Derivatives</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#parameters">Parameters</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#schemes">Schemes</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#example">Example</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#4-second-order-derivatives">4. Second-Order Derivatives</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#41-laplacian">4.1 Laplacian</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#42-hessian">4.2 Hessian</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#43-log-laplacian-of-gaussian">4.3 LoG (Laplacian of Gaussian)</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#44-dog-difference-of-gaussian">4.4 DoG (Difference of Gaussian)</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#summary">Summary</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#5-adaptive-filtering-sigma-filter">5. Adaptive Filtering (Sigma Filter)</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#1-gradient-calculation">1. Gradient Calculation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#2-sum-of-gradients">2. Sum of Gradients</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#3-adaptive-weighting">3. Adaptive Weighting</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#4-smoothing-operation">4. Smoothing Operation</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#connection-to-neuroscience">Connection to Neuroscience</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#6-adaptive-window-filters">6. Adaptive Window Filters</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#61-nagao-filter">6.1 Nagao Filter</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#62-kuwahara-filter">6.2 Kuwahara Filter</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#7-deriche-recursive-filters">7. Deriche Recursive Filters</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#71-smoothing-0-th-order">7.1 Smoothing (0-th Order)</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#72-gradient-computation-1st-order">7.2 Gradient Computation (1st Order)</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#73-laplacian-computation-2nd-order">7.3 Laplacian Computation (2nd Order)</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#8-frequency-domain-filtering">8. Frequency Domain Filtering</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#81-using-cimgfft">8.1 Using CImg&lt;&gt;::FFT()</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#load-the-image-and-convert-to-grayscale">Load the image and convert to grayscale</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#resize-the-image">Resize the image</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#compute-the-fft">Compute the FFT</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#process-magnitude">Process Magnitude</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#optional-compute-inverse-fft">(Optional) Compute Inverse FFT</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#82-butterworth-filters">8.2 Butterworth Filters</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#83-gaussian-filters">8.3 Gaussian Filters</a>
        <ul>
    <li class="toctree-l4"><a class="reference internal" href="#perform-the-fast-fourier-transform-fft">Perform the Fast Fourier Transform (FFT)</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#create-the-gaussian-mask">Create the Gaussian Mask</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#zero-shift-the-gaussian-mask">Zero Shift the Gaussian Mask</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#apply-the-filter">Apply the Filter</a>
    </li>
    <li class="toctree-l4"><a class="reference internal" href="#inverse-fft-and-normalize">Inverse FFT and Normalize</a>
    </li>
        </ul>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#9-diffusion-filtering">9. Diffusion Filtering</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../appendix_1/">Appendix 1 - Math Expressions in CImg's Fill Method</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Digital Image Processing Notes</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a> &raquo;</li>
      <li>5. Filtering</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/tonyfu97/Digital-Image-Processing/blob/master/docs/05_filtering.md" class="icon icon-github"> Edit on GitHub</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="filtering-learning-reflection">Filtering - Learning Reflection</h1>
<p><strong>Author</strong>: Tony Fu<br />
<strong>Date</strong>: August 21, 2023<br />
<strong>Device</strong>: MacBook Pro 16-inch, Late 2021 (M1 Pro)<br />
<strong>Code</strong>: <a href="https://github.com/tonyfu97/Digital-Image-Processing/tree/main/05_filtering">GitHub</a><br />
<strong>Reference</strong>: Chapter 5 <a href="https://www.amazon.com/Digital-Image-Processing-Implementing-Algorithms/dp/1032347538"><em>Digital Image Processing with C++: Implementing Reference Algorithms with the CImg Library</em> by Tschumperl√©, Tilmant, Barra</a></p>
<h2 id="1-convolution">1. Convolution</h2>
<pre><code class="language-cpp">CImg&lt;&gt; sobel(3, 3, 1, 1, 0);
sobel(0, 0) = -1; sobel(0, 1) = -2; sobel(0, 2) = -1;
sobel(1, 0) = 0;  sobel(1, 1) = 0;  sobel(1, 2) = 0;
sobel(2, 0) = 1;  sobel(2, 1) = 2;  sobel(2, 2) = 1;
imgIn.convolve(sobel);
</code></pre>
<p>The above code snippet shows how to perform a convolution on an image with a 3x3 Sobel filter. The result is shown below:</p>
<ul>
<li><strong>Original</strong>:</li>
</ul>
<p><img alt="original" src="../images/lighthouse.png" /></p>
<ul>
<li><strong>Convolution</strong>:</li>
</ul>
<p><img alt="conv" src="../results/05/lighthouse_conv.png" /></p>
<h3 id="boundary-conditions">Boundary Conditions</h3>
<p>Boundary conditions specify how to handle the edges and can be specified using the <code>const usigned int boundary_conditions</code> parameter of the <code>convolve()</code> method. The four boundary conditions provided by the CImg library have specific meanings:</p>
<ol>
<li>
<p><strong>Dirichlet (0):</strong> The pixels outside the image boundaries are considered to be zero. This creates a sort of "hard" edge around the image and can lead to noticeable artifacts along the borders.</p>
</li>
<li>
<p><strong>Neumann (1) (default):</strong> The value of the border pixels is extended outside the image boundaries. Essentially, this reflects the gradient at the border, assuming that the intensity of the image doesn't change beyond the edge. This is the default boundary condition in CImg and tends to provide visually acceptable results.</p>
</li>
<li>
<p><strong>Periodic (2):</strong> The image is treated as if it were tiling the plane in a repeated pattern. This means that the pixels on the right edge of the image are used as the boundary condition for the left edge, and the pixels on the bottom are used for the top. This can create seamless transitions but can also lead to strange effects if the image does not naturally tile.</p>
</li>
<li>
<p><strong>Mirror (3):</strong> The pixels outside the image boundaries are determined by mirroring the pixels inside the boundaries. Imagine folding the image over at its edges, so the pixels just inside the border are duplicated just outside the border. This can create a more visually smooth transition at the edges but may not be appropriate for all types of images.</p>
</li>
</ol>
<h2 id="2-median-fitler">2. Median Fitler</h2>
<pre><code class="language-cpp">img.blur_median(3);
</code></pre>
<p>The above code snippet shows how to perform a median filter on an image with a 3x3 window. The result is shown below:</p>
<ul>
<li><strong>Origin</strong>:</li>
</ul>
<p><img alt="coins_threshold" src="../results/05/coins_threshold.png" /></p>
<ul>
<li><strong>Median Filter</strong>:</li>
</ul>
<p><img alt="median" src="../results/05/coins_median.png" /></p>
<h3 id="order-statistic-os-filter">Order-Statistic (OS) Filter</h3>
<p>An <a href="https://ieeexplore.ieee.org/document/1164247">OS filter (Bovik, Huang, and Munson, 1983)</a> is a non-linear filter that computes a linear combination of these sorted values:</p>
<p>
<script type="math/tex; mode=display"> F = w_1 \cdot s_1 + w_2 \cdot s_2 + \ldots + w_n \cdot s_n </script>
</p>
<p>where <script type="math/tex"> w_i </script> are the weights that define how much each ordered value contributes to the final result, and <script type="math/tex"> s_i </script> are the sorted values of the neighborhood pixels.</p>
<h2 id="3-first-order-derivatives">3. First-Order Derivatives</h2>
<p>The <code>get_gradient</code> function computes the image gradient along specified axes using different numerical schemes.</p>
<h3 id="parameters">Parameters</h3>
<ul>
<li><strong><code>axes</code></strong>: Axes considered for the gradient computation (e.g., "xy").</li>
<li><strong><code>scheme</code></strong>: Numerical scheme used for the gradient computation. Options are:</li>
</ul>
<h3 id="schemes">Schemes</h3>
<ol>
<li>
<p><strong>Backward Finite Differences (<code>scheme = -1</code>)</strong>
   Computes the gradient using backward finite differences:</p>
<p>
<script type="math/tex; mode=display">
\text{grad}[pos] = \text{data}[pos] - \text{data}[pos - \text{off}]
</script>
</p>
</li>
<li>
<p><strong>Central Finite Differences (<code>scheme = 0</code>)</strong>
   Computes the gradient using central finite differences:</p>
<p>
<script type="math/tex; mode=display">
\text{grad}[pos] = \frac{\text{data}[pos + \text{off}] - \text{data}[pos - \text{off}]}{2}
</script>
</p>
</li>
<li>
<p><strong>Forward Finite Differences (<code>scheme = 1</code>)</strong>
   Computes the gradient using forward finite differences:</p>
<p>
<script type="math/tex; mode=display">
\text{grad}[pos] = \text{data}[pos + \text{off}] - \text{data}[pos]
</script>
</p>
</li>
<li>
<p><strong>Sobel Scheme (<code>scheme = 2</code>)</strong>
   Utilizes Sobel operators to compute the gradient.</p>
</li>
<li>
<p><strong>Rotation Invariant Scheme (<code>scheme = 3</code>)</strong>
   Uses a rotation-invariant kernels:</p>
<p>
<script type="math/tex; mode=display">
\text{Rotation-Invariant}_{x} = \begin{bmatrix} -a & -b & -a \\ 0 & 0 & 0 \\ a & b & a \end{bmatrix}\\
\text{Rotation-Invariant}_{y} = \text{Rotation-Invariant}_{x}^T
</script>
</p>
<p>where <script type="math/tex"> a = 0.25 \times (2 - \sqrt{2}) </script> and <script type="math/tex"> b = 0.5 \times (\sqrt{2} - 1) </script>. </p>
</li>
<li>
<p><strong>Deriche Recursive Filter</strong>: Introduced later.</p>
</li>
<li><strong>Van Vliet Recursive Filter</strong>: Introduced later.</li>
</ol>
<table>
<thead>
<tr>
<th>Scheme</th>
<th>Applications</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr>
<td>Backward finite differences</td>
<td>General-purpose</td>
<td>Simple, easy to implement</td>
<td>Less accurate, sensitive to noise</td>
</tr>
<tr>
<td>Centered finite differences</td>
<td>General-purpose</td>
<td>More accurate than forward/backward</td>
<td>Sensitive to noise</td>
</tr>
<tr>
<td>Forward finite differences</td>
<td>General-purpose</td>
<td>Simple, easy to implement</td>
<td>Less accurate, sensitive to noise</td>
</tr>
<tr>
<td>Using Sobel kernels</td>
<td>Edge detection</td>
<td>Good at capturing edges, less noisy</td>
<td>Can miss fine details</td>
</tr>
<tr>
<td>Using rotation invariant</td>
<td>Edge detection, texture analysis</td>
<td>Rotation invariant, captures subtle edges</td>
<td>More computationally expensive</td>
</tr>
<tr>
<td>Using Deriche recursive filter</td>
<td>Smoothing, edge detection</td>
<td>Smooths noise, good edge detection</td>
<td>Computationally expensive</td>
</tr>
<tr>
<td>Using Van Vliet recursive filter</td>
<td>Smoothing, edge detection</td>
<td>Smooths noise, efficient computation</td>
<td>Might blur some edges</td>
</tr>
</tbody>
</table>
<h3 id="example">Example</h3>
<pre><code class="language-cpp">// Gradient approximation using centered finite differences.
CImgList&lt;&gt; grad = imageIn.get_gradient();

// Norm and phase of the gradient.
CImg&lt;&gt;
    norm = (grad[0].get_sqr() + grad[1].get_sqr()).sqrt(),
    phi = grad[1].get_atan2(grad[0]);
</code></pre>
<ul>
<li><strong>Original</strong></li>
</ul>
<p><img alt="original" src="../images/lighthouse.png" /></p>
<ul>
<li><strong>Gradient X</strong></li>
</ul>
<p><img alt="grad_x" src="../results/05/lighthouse_gradient_x.png" /></p>
<ul>
<li><strong>Gradient Y</strong></li>
</ul>
<p><img alt="grad_y" src="../results/05/lighthouse_gradient_y.png" /></p>
<ul>
<li><strong>Gradient Norm</strong></li>
</ul>
<p><img alt="grad_norm" src="../results/05/lighthouse_gradient_norm.png" /></p>
<ul>
<li><strong>Gradient Phase</strong></li>
</ul>
<p><img alt="grad_phi" src="../results/05/lighthouse_gradient_phi.png" /></p>
<h2 id="4-second-order-derivatives">4. Second-Order Derivatives</h2>
<p>Second-order derivatives are useful for detecting edges (when combined with thresholding and non-maximum suppression). However, they are more commonly used for feature detection, a topic that will be covered in Chapter 6.</p>
<h3 id="41-laplacian">4.1 Laplacian</h3>
<p>The Laplacian operator calculates the divergence of the gradient of the image, effectively highlighting regions where there is a rapid change in intensity.</p>
<pre><code class="language-cpp">void Laplacian(CImg&lt;&gt; &amp;imageIn)
{
    CImg&lt;&gt; laplacian = imageIn.get_laplacian();
    laplacian.normalize(0, 255).save(&quot;./results/lighthouse_laplacian.png&quot;);
}
</code></pre>
<p>Mathematically, it is represented as:</p>
<p>
<script type="math/tex; mode=display"> \nabla^2 f = \frac{{\partial^2 f}}{{\partial x^2}} + \frac{{\partial^2 f}}{{\partial y^2}} </script>
</p>
<p><img alt="laplacian" src="../results/05/lighthouse_laplacian.png" /></p>
<h3 id="42-hessian">4.2 Hessian</h3>
<p>The Hessian matrix consists of the second-order partial derivatives of the image.</p>
<pre><code class="language-cpp">void Hessian(CImg&lt;&gt; &amp;imageIn)
{
    CImg&lt;&gt; Ixx = imageIn.get_hessian(&quot;xx&quot;)[0];
    // ... rest of the code ...
}
</code></pre>
<p>It is mathematically expressed as:</p>
<p>
<script type="math/tex; mode=display"> \mathbf{H} = \begin{bmatrix} \frac{{\partial^2 f}}{{\partial x^2}} & \frac{{\partial^2 f}}{{\partial x \partial y}} \\ \frac{{\partial^2 f}}{{\partial y \partial x}} & \frac{{\partial^2 f}}{{\partial y^2}} \end{bmatrix} </script>
</p>
<ul>
<li>
<p><strong>Hessian XX</strong>
<img alt="hessian_xx" src="../results/05/lighthouse_hessian_xx.png" /></p>
</li>
<li>
<p><strong>Hessian YY</strong>
<img alt="hessian_yy" src="../results/05/lighthouse_hessian_yy.png" /></p>
</li>
<li>
<p><strong>Hessian XY</strong>
<img alt="hessian_xy" src="../results/05/lighthouse_hessian_xy.png" /></p>
</li>
</ul>
<h3 id="43-log-laplacian-of-gaussian">4.3 LoG (Laplacian of Gaussian)</h3>
<p>LoG combines Gaussian smoothing with the Laplacian operator.</p>
<pre><code class="language-cpp">void LoG(CImg&lt;&gt; &amp;imageIn)
{
    CImg&lt;&gt; log = imageIn.get_blur(2).laplacian();
    // ... rest of the code ...
}
</code></pre>
<p>The expression for LoG is:</p>
<p>
<script type="math/tex; mode=display"> \nabla^2 (G * f) = \nabla^2 G * f </script>
</p>
<p>where <script type="math/tex"> G </script> is the Gaussian function.</p>
<p><img alt="log" src="../results/05/lighthouse_log.png" /></p>
<h3 id="44-dog-difference-of-gaussian">4.4 DoG (Difference of Gaussian)</h3>
<p>DoG approximates the LoG by taking the difference between two blurred images with different standard deviations.</p>
<pre><code class="language-cpp">void DoG(CImg&lt;&gt; &amp;imageIn)
{
    CImg&lt;&gt; gauss1 = imageIn.get_blur(1);
    CImg&lt;&gt; gauss2 = imageIn.get_blur(2);
    CImg&lt;&gt; dog = gauss1 - gauss2;
    // ... rest of the code ...
}
</code></pre>
<p>Mathematically, DoG is represented as:</p>
<p>
<script type="math/tex; mode=display"> \text{DoG} = (G_{\sigma_1} * f) - (G_{\sigma_2} * f) </script>
</p>
<p>where <script type="math/tex"> G_{\sigma_1} </script> and <script type="math/tex"> G_{\sigma_2} </script> are Gaussian functions with standard deviations <script type="math/tex"> \sigma_1 </script> and <script type="math/tex"> \sigma_2 </script>, respectively.</p>
<p><img alt="dog" src="../results/05/lighthouse_dog.png" /></p>
<h3 id="summary">Summary</h3>
<table>
<thead>
<tr>
<th>2nd-Order Derivative</th>
<th>Applications</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Laplacian</strong></td>
<td>Edge Detection</td>
<td>Sensitive to edges, Simple computation</td>
<td>Noisy, Sensitive to noise</td>
</tr>
<tr>
<td><strong>Hessian</strong></td>
<td>Feature Detection</td>
<td>Captures second-order information, Rich features</td>
<td>Computationally expensive</td>
</tr>
<tr>
<td><strong>LoG (Laplacian of Gaussian)</strong></td>
<td>Edge Detection, Feature Detection</td>
<td>Reduces noise, Effective edge detection</td>
<td>Slower than DoG</td>
</tr>
<tr>
<td><strong>DoG (Difference of Gaussian)</strong></td>
<td>Edge Detection, Approximation of LoG</td>
<td>Faster approximation of LoG</td>
<td>Less accurate than LoG</td>
</tr>
</tbody>
</table>
<h2 id="5-adaptive-filtering-sigma-filter">5. Adaptive Filtering (Sigma Filter)</h2>
<p>Traditional smoothing filters often blur the edges along with reducing noise, causing a loss of important details. On the other hand, adaptive or other nonlinear filters like the sigma filter promise to reduce noise in images while preserving edges and contours. The method is based on the principle of weighting the influence of neighboring pixels based on the gradient, similar to some normalization or shunting mechanisms found in neuroscience.</p>
<h3 id="1-gradient-calculation">1. Gradient Calculation</h3>
<p>First, the code calculates the gradient of the input image using the <code>get_gradient()</code> method:</p>
<pre><code class="language-cpp">CImgList&lt;&gt; g = imgIn.get_gradient();
CImg&lt;&gt; grad = (g[0].get_sqr() + g[1].get_sqr()).sqrt();
</code></pre>
<p>The gradient, <script type="math/tex">\nabla f</script>, quantifies the rate of change in pixel values across the image and is given by the formula:</p>
<p>
<script type="math/tex; mode=display">
\nabla f = \sqrt{{\left(\frac{{\partial f}}{{\partial x}}\right)}^2 + {\left(\frac{{\partial f}}{{\partial y}}\right)}^2}
</script>
</p>
<h3 id="2-sum-of-gradients">2. Sum of Gradients</h3>
<p>Next, the sum of gradients in a 3x3 neighborhood is computed:</p>
<pre><code class="language-cpp">CImg&lt;&gt; Sgrad = grad.get_convolve(CImg&lt;&gt;(3, 3, 1, 1, 1));
</code></pre>
<p>This step convolves the gradient with a 3x3 filter, summing the neighboring gradients, effectively measuring local variations in pixel intensities.</p>
<h3 id="3-adaptive-weighting">3. Adaptive Weighting</h3>
<p>The code then applies adaptive weighting using the following lines:</p>
<pre><code class="language-cpp">float epsilon = 100;
CImg&lt;&gt; rap = imgIn.get_div(grad + epsilon);
</code></pre>
<p>Here, the division acts as a weighting coefficient, with the epsilon term preventing division by zero. The weight of a pixel in the sum is inversely proportional to the local gradient:</p>
<p>
<script type="math/tex; mode=display">
\text{{weight}} = \frac{{f}}{{\nabla f + \epsilon}}
</script>
</p>
<p>In <code>rap</code>, the pixels with high gradients are weighted less, but in this case, less actually means darker pixels! So, this code is emphasizing the edges and contours of the image.</p>
<p>We started with this image:</p>
<p><img alt="noise" src="../results/05/lighthouse_noise.png" /></p>
<p>And ended up with this:</p>
<p><img alt="rap" src="../results/05/lighthouse_rap.png" /></p>
<h3 id="4-smoothing-operation">4. Smoothing Operation</h3>
<p>The smoothing operation is performed in the following lines:</p>
<pre><code class="language-cpp">CImg_3x3(I, float); // declare Ipp, Ipc, etc.
cimg_for3x3(rap, x, y, 0, 0, I, float)
    imgOut(x, y) = (Ipp + Ipc + Ipn + Icp + Icc + Icn + Inp + Inc + Inn) / (Sgrad(x, y) + epsilon);
</code></pre>
<p>Here, <code>CImg_3x3(I, float);</code> declares variables like <code>Ipp</code>, <code>Ipc</code>, etc., representing the neighboring pixels. The <code>cimg_for3x3</code> macro iterates through the image, applying the smoothing operation. The numerator is a simple average (actually sum) filter, and the bottom term is larger for pixels with high gradients. Therefore, we emphasize the edges and contours again by making those pixels darker.</p>
<p>The final formula for smoothing is:</p>
<p>
<script type="math/tex; mode=display">
\text{{imgOut}}(x, y) = \frac{{\sum \text{{neighboring pixels}}}}{{\text{{Sgrad}}(x, y) + \epsilon}}
</script>
</p>
<p><img alt="sigma" src="../results/05/lighthouse_sigma.png" /></p>
<p>As you can see, the noise are amplified along with the edges are emphasized. This adaptive sigma filter may not be the best choice for this image.</p>
<p>The somewhat cartoon-like appearance of the final output image is a common effect of adaptive smoothing techniques like the sigma filter. By emphasizing edges and smoothing uniform areas, the image can take on a more stylized or abstract appearance. </p>
<h3 id="connection-to-neuroscience">Connection to Neuroscience</h3>
<p>The adaptive nature of this method is akin to the way some neurons modulate their response based on local activity. It aligns with principles observed in neuroscience where the influence of neighboring neurons is normalized or shunted based on the local context, allowing for a balance between sensitivity to stimuli and adaptation to the local environment.</p>
<h2 id="6-adaptive-window-filters">6. Adaptive Window Filters</h2>
<p>Adaptive window filters are smart filters that change their behavior based on the characteristics of the area they are working on. They look at each pixel and decide the best way to smooth or sharpen it based on the pixels around it. There are different ways to do this, and here are three examples using the following noisy image (Gaussian noise <script type="math/tex"> \sigma = 40 </script>):</p>
<p><img alt="noise_40" src="../results/05/lighthouse_noise40.png" /></p>
<h3 id="61-nagao-filter">6.1 Nagao Filter</h3>
<p>Imagine you have a small grid (usually 5x5) around a pixel in the middle. In this grid, you create 9 different windows (smaller groups of pixels), each containing 9 pixels. Here we first intialize the windows:</p>
<pre><code class="language-cpp">CImgList&lt;unsigned char&gt; Nagao(9, 5, 5, 1, 1, 0);
Nagao(0, 0, 0) = Nagao(0, 0, 1) = Nagao(0, 0, 2) = Nagao(0, 0, 3) =
    Nagao(0, 0, 4) = Nagao(0, 1, 1) = Nagao(0, 1, 2) = Nagao(0, 1, 3) =
        Nagao(0, 2, 2) = 1;
for (int i = 1; i &lt; 4; ++i)
    Nagao[i] = Nagao[0].get_rotate(i * 90);

Nagao(4, 1, 1) = Nagao(4, 1, 2) = Nagao(4, 1, 3) = Nagao(4, 2, 1) =
    Nagao(4, 2, 2) = Nagao(4, 2, 3) = Nagao(4, 3, 1) = Nagao(4, 3, 2) =
        Nagao(4, 3, 3) = 1;

Nagao(5, 0, 0) = Nagao(5, 0, 1) = Nagao(5, 0, 2) = Nagao(5, 1, 0) =
    Nagao(5, 1, 1) = Nagao(5, 1, 2) = Nagao(5, 2, 0) = Nagao(5, 2, 1) =
        Nagao(5, 2, 2) = 1;
for (int i = 1; i &lt; 4; ++i)
    Nagao[5 + i] = Nagao[5].get_rotate(i * 90);
</code></pre>
<p><img alt="nagao_windows" src="../results/05/nagao_windows.png" /></p>
<p>For each window:</p>
<ul>
<li>You calculate the average color (mean) and how much the colors vary (variance).</li>
<li>You pick the window where the colors vary the least (smallest variance).</li>
<li>You replace the middle pixel with the average color from that chosen window.</li>
</ul>
<p>Here is the code:</p>
<pre><code class="language-cpp">CImg&lt;&gt;
    mu(9, 1, 1, 1, 0),
    sigma(9, 1, 1, 1, 0),
    st,
    N(5, 5);
CImg&lt;int&gt; permutations;
cimg_for5x5(imgIn, x, y, 0, 0, N, float)
{
    CImgList&lt;&gt; res(9);
    for (int i = 0; i &lt; 9; ++i)
    {
        res[i] = N.get_mul(Nagao[i]);
        st = res[i].get_stats();
        mu[i] = st[2];
        sigma[i] = st[3];
    }
    // Searching minimal variance.
    sigma.sort(permutations);
    imgOut(x, y) = mu[permutations[0]];
}
</code></pre>
<p><img alt="nagao" src="../results/05/lighthouse_nagao.png" /></p>
<p>This method helps to keep the details in the image while reducing noise.</p>
<h3 id="62-kuwahara-filter">6.2 Kuwahara Filter</h3>
<p>The Kuwahara filter is like the Nagao filter, but only uses windows 5 - 8 of Nagao filter. It's just a variation that might work better on certain types of images. The basic idea of finding the least varying window and using its average color remains the same.</p>
<p><img alt="kuwahara_windows" src="../results/05/kuwahara_windows.png" /></p>
<p><img alt="kuwahara" src="../results/05/lighthouse_kuwahara.png" /></p>
<h2 id="7-deriche-recursive-filters">7. Deriche Recursive Filters</h2>
<p>John Canny's work on edge detection is not only confined to the Canny edge detector but also includes mathematical foundations for defining the criteria of an effective edge detector. Canny outlined three criteria: good detection, good localization, and a single response. The first two criteria can be combined to yield a so-called <em>Canny criterion value</em>, adding mathematical rigor to the field of edge detection.</p>
<p>The <a href="https://en.wikipedia.org/wiki/Deriche_edge_detector">Deriche recursive filter</a> is an recursive solution to Canny's criteria. However, in the book, Deriche filter is presented as a family of recursive (and potentially more efficient) alternatives to smoothing operation (0-th order), gradient computation (1st order), and Laplacian computation (2nd order).</p>
<p>The function <code>CImg&lt;T&gt;&amp; deriche(const float sigma, const unsigned int order=0, const char axis='x')</code> filter applies in one direction at once. <code>sigma</code> is the standard deviation of the filter, while <code>order</code> is the order of the derivative to compute. <code>axis</code> is the axis along which the filter is applied.</p>
<h3 id="71-smoothing-0-th-order">7.1 Smoothing (0-th Order)</h3>
<pre><code class="language-cpp">CImg&lt;&gt; img_deriche0 = imgIn.get_deriche(SIGMA, 0, 'x');
img_deriche0.deriche(SIGMA, 0, 'y');
</code></pre>
<p><img alt="deriche0" src="../results/05/lighthouse_deriche0.png" /></p>
<h3 id="72-gradient-computation-1st-order">7.2 Gradient Computation (1st Order)</h3>
<pre><code class="language-cpp">CImg&lt;&gt; img_deriche1 = imgIn.get_deriche(SIGMA, 1, 'x');
img_deriche1.deriche(SIGMA, 1, 'y');
CImg&lt;&gt; img_deriche1_norm = (img_deriche1.get_sqr() += img_deriche1.get_sqr()).sqrt();
</code></pre>
<p><img alt="deriche1" src="../results/05/lighthouse_deriche1.png" /></p>
<h3 id="73-laplacian-computation-2nd-order">7.3 Laplacian Computation (2nd Order)</h3>
<pre><code class="language-cpp">CImg&lt;&gt; img_deriche2_x = imgIn.get_deriche(SIGMA, 2, 'x');
CImg&lt;&gt; img_deriche2_y = imgIn.get_deriche(SIGMA, 2, 'y');
CImg&lt;&gt; img_deriche2_laplacian = img_deriche2_x + img_deriche2_y;
</code></pre>
<p><img alt="deriche2" src="../results/05/lighthouse_deriche2.png" /></p>
<h2 id="8-frequency-domain-filtering">8. Frequency Domain Filtering</h2>
<h3 id="81-using-cimgfft">8.1 Using <code>CImg&lt;&gt;::FFT()</code></h3>
<h4 id="load-the-image-and-convert-to-grayscale">Load the image and convert to grayscale</h4>
<pre><code class="language-cpp">CImg&lt;unsigned char&gt; img(&quot;../images/lighthouse.png&quot;);
CImg&lt;&gt; lum = img.get_norm().blur(0.75f);
</code></pre>
<h4 id="resize-the-image">Resize the image</h4>
<p>FFT requires dimensions to be a power of 2, so resize the image to meet this requirement.</p>
<pre><code class="language-cpp">int width = 1 &lt;&lt; static_cast&lt;int&gt;(std::ceil(std::log2(lum.width())));
int height = 1 &lt;&lt; static_cast&lt;int&gt;(std::ceil(std::log2(lum.height())));
lum.resize(width, height, -100, -100, 0);
</code></pre>
<h4 id="compute-the-fft">Compute the FFT</h4>
<pre><code class="language-cpp">CImgList&lt;&gt; fft = lum.get_FFT();
</code></pre>
<h4 id="process-magnitude">Process Magnitude</h4>
<p>Take the logarithm of the magnitude part to better visualize it, and then shift the zero frequency component to the center of the spectrum.</p>
<pre><code class="language-cpp">CImg&lt;&gt; magnitude(fft[0]);
magnitude += 1; // Avoid log(0)
magnitude.log();
magnitude.shift(magnitude.width() / 2, magnitude.height() / 2, 0, 0, 2);
</code></pre>
<h4 id="optional-compute-inverse-fft">(Optional) Compute Inverse FFT</h4>
<p>Perform the inverse FFT to recover the original image.</p>
<pre><code class="language-cpp">CImg&lt;&gt; img_ifft = fft.get_FFT(true)[0];
</code></pre>
<h3 id="82-butterworth-filters">8.2 Butterworth Filters</h3>
<p>The idea of frequency-domain filtering involves first transforming the image into the frequency domain, then multiplying the image with a mask, and finally transforming the image back to the spatial domain. Theoretically, this is equivalent to convolving the image with the mask in the spatial domain. It might sound like a lot of extra work, but the Fast Fourier Transform (FFT) makes it much faster. However, you need to be mindful of artifacts such as the Gibbs phenomenon, which can be reduced by using appropriate windowing functions.</p>
<p>Butterworth filters are a family of filters characterized by a maximally flat frequency response. They can be applied in both analog and digital forms, and in both time and frequency domains.</p>
<p>In the analog frequency domain, the 2D transfer function for a Butterworth low-pass filter can be represented as:
<script type="math/tex; mode=display"> H(u,v) = \frac{1}{1 + \left( \frac{D(u,v)}{D_0} \right)^{2n}} </script>
where <script type="math/tex"> D(u,v) = \sqrt{u^2 + v^2} </script> is the distance from the origin in the frequency domain, and <script type="math/tex"> D_0 </script> is the cutoff frequency. The parameter <script type="math/tex"> n </script> is the order of the filter. Increasing <script type="math/tex"> n </script> will result in a steeper roll-off, but at the expense of increased complexity, potential instability, and possible phase distortion.</p>
<p>In the spatial domain, you would have to use the inverse Fourier transform to obtain a corresponding difference equation.</p>
<h3 id="83-gaussian-filters">8.3 Gaussian Filters</h3>
<p>The Gaussian filter can be implemented in both time and frequency domains Here's how to apply a Gaussian filter in the frequency domain:</p>
<h4 id="perform-the-fast-fourier-transform-fft">Perform the Fast Fourier Transform (FFT)</h4>
<p>First, compute the FFT of the input image.</p>
<pre><code class="language-cpp">CImgList&lt;&gt; fImg = imgIn.get_FFT();
</code></pre>
<h4 id="create-the-gaussian-mask">Create the Gaussian Mask</h4>
<p>Construct the frequency response of the filter using the Gaussian function. The Gaussian mask is defined in the frequency domain, and <code>sigma</code> is the standard deviation controlling the spread of the Gaussian function. In the frequency domain, the filter is described by the Gaussian function:</p>
<p>
<script type="math/tex; mode=display"> H(u, v) = 2\pi \sigma^2 \exp\left(-2\pi^2\sigma^2\left(\left(\frac{u}{W} - 0.5\right)^2 + \left(\frac{v}{H} - 0.5\right)^2\right)\right) </script>
</p>
<p>Here, <script type="math/tex"> W </script> and <script type="math/tex"> H </script> are the width and height of the image, <script type="math/tex"> \sigma^2 </script> is the squared standard deviation, and <script type="math/tex"> (u,v) </script> are the frequency coordinates.</p>
<pre><code class="language-cpp">CImg&lt;&gt; gaussMask(imgIn.width(), imgIn.height());
float sigma2 = cimg::sqr(sigma);
cimg_forXY(gaussMask, x, y)
{
    float fx = x / (float)imgIn.width() - 0.5f, fx2 = cimg::sqr(fx),
          fy = y / (float)imgIn.height() - 0.5f,
          fy2 = cimg::sqr(fy);
    gaussMask(x, y) = 2 * cimg::PI * sigma2 *
                      std::exp(-2 * cimg::sqr(cimg::PI) * sigma2 * (fx2 + fy2));
}
</code></pre>
<h4 id="zero-shift-the-gaussian-mask">Zero Shift the Gaussian Mask</h4>
<p>Shift the Gaussian mask by half its width and height to center the zero frequency.</p>
<pre><code class="language-cpp">// Zero shift.
gaussMask.shift(-imgIn.width() / 2, -imgIn.height() / 2, 0, 0, 2);
</code></pre>
<h4 id="apply-the-filter">Apply the Filter</h4>
<p>Perform the element-wise multiplication of the Fourier Transformed image and the Gaussian mask.</p>
<pre><code class="language-cpp">// Filtering
cimglist_for(fImg, k)
    fImg[k].mul(gaussMask);
</code></pre>
<h4 id="inverse-fft-and-normalize">Inverse FFT and Normalize</h4>
<p>Transform back to the spatial domain via inverse FFT and normalize the result.</p>
<pre><code class="language-cpp">// Inverse FFT and real part.
return fImg.get_FFT(true)[0].normalize(0, 255);
</code></pre>
<p><img alt="gaussian" src="../results/05/lighthouse_gaussian.png" /></p>
<h2 id="9-diffusion-filtering">9. Diffusion Filtering</h2>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../04_morphology/" class="btn btn-neutral float-left" title="4. Morphology"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../appendix_1/" class="btn btn-neutral float-right" title="Appendix 1 - Math Expressions in CImg's Fill Method">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
      <p>Copyright &copy; 2023 Tony Fu</p>
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/tonyfu97/Digital-Image-Processing" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../04_morphology/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../appendix_1/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
